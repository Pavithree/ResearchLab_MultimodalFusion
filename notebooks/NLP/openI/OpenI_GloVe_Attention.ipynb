{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2eef563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neattext in /opt/anaconda3/lib/python3.8/site-packages (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "!pip install neattext\n",
    "import neattext.functions as nfx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.layers import Embedding,Dense,LSTM,Bidirectional,GlobalMaxPooling1D,Input,Dropout\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.layers import SpatialDropout1D, GlobalAveragePooling1D, Concatenate, concatenate\n",
    "from keras.layers import Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb2cd86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"openLDF.csv\");\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels']= df[['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'Normal']].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d3318",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data,test_data=train_test_split(df,test_size=0.2,random_state=10)\n",
    "train_data = df[df[\"split\"] == \"train\"]\n",
    "test_data = df[df[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_length=[]\n",
    "    cleaned_text=[]\n",
    "    for sent in tqdm(text):\n",
    "        sent=sent.lower()\n",
    "        sent=nfx.remove_special_characters(sent)\n",
    "        sent=nfx.remove_stopwords(sent)\n",
    "#         sent=nfx.remove_shortwords(sent)\n",
    "        text_length.append(len(sent.split()))\n",
    "        cleaned_text.append(sent)\n",
    "    return cleaned_text,text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2912/2912 [00:00<00:00, 26728.12it/s]\n",
      "100%|██████████| 772/772 [00:00<00:00, 21556.94it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_train_text, cleaned_train_text_length = clean_text(train_data.TXT)\n",
    "cleaned_test_text, cleaned_test_text_length = clean_text(test_data.TXT)\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_train_text)\n",
    "train_text_seq=tokenizer.texts_to_sequences(cleaned_train_text)\n",
    "train_text_pad=pad_sequences(train_text_seq,maxlen=50)\n",
    "test_text_seq=tokenizer.texts_to_sequences(cleaned_test_text)\n",
    "test_text_pad=pad_sequences(test_text_seq,maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_data[\"labels\"].to_list()\n",
    "test_labels = test_data[\"labels\"].to_list()\n",
    "train_labels = np.array(train_labels)\n",
    "#train_labels = train_labels.reshape(1,-1)\n",
    "test_labels = np.array(test_labels)\n",
    "#test_labels = test_labels.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download glove.840B.300d.pkl from https://nlp.stanford.edu/projects/glove/\n",
    "with open('glove.840B.300d.pkl', 'rb') as fp:\n",
    "    glove_embedding = pickle.load(fp)\n",
    "v=len(tokenizer.word_index)\n",
    "embedding_matrix=np.zeros((v+1,300), dtype=float)\n",
    "for word,idx in tokenizer.word_index.items():\n",
    "    embedding_vector=glove_embedding.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx]=embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2077de",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=EarlyStopping(patience=5)\n",
    "reducelr=ReduceLROnPlateau(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def __call__(self, lstm, state_h):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(state_h, 1)\n",
    "          \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = tf.nn.tanh(\n",
    "            self.W1(lstm) + self.W2(hidden_with_time_axis))\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "          \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * lstm\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 300)      538200      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 50, 256), (N 330240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][2]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 1, 256)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 50, 10)       2570        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 10)        2570        tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 50, 10)       0           dense_10[0][0]                   \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.tanh (TFOpLambda)       (None, 50, 10)       0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 50, 1)        11          tf.math.tanh[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.softmax (TFOpLambda)      (None, 50, 1)        0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 50, 256)      0           tf.nn.softmax[0][0]              \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 256)          0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          32896       tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 15)           1935        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 908,422\n",
      "Trainable params: 370,222\n",
      "Non-trainable params: 538,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_output = 15\n",
    "sequence_input = Input(shape=(50,))\n",
    "embedded_sequences =  Embedding(v+1,300, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "(lstm, forward_h, backward_h) = Bidirectional(GRU(128,return_sequences=True, return_state=True, dropout=0.1,\n",
    "recurrent_dropout=0.1))(embedded_sequences)\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "context_vector, attention_weights = Attention(10)(lstm, state_h)\n",
    "dense1 = Dense(128, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.1)(dense1)\n",
    "output = Dense(n_output, activation=\"softmax\")(dropout)\n",
    "model = keras.Model(inputs=sequence_input, outputs=output)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['Accuracy', 'Precision', 'Recall'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 [==============================] - 20s 337ms/step - loss: 0.1999 - Accuracy: 0.7301 - precision: 0.7619 - recall: 0.5680 - val_loss: 0.1380 - val_Accuracy: 0.7215 - val_precision: 0.7402 - val_recall: 0.6105\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 15s 316ms/step - loss: 0.0994 - Accuracy: 0.7874 - precision: 0.8480 - recall: 0.6846 - val_loss: 0.1065 - val_Accuracy: 0.7500 - val_precision: 0.8764 - val_recall: 0.6172\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 15s 327ms/step - loss: 0.0813 - Accuracy: 0.8273 - precision: 0.8912 - recall: 0.7233 - val_loss: 0.0912 - val_Accuracy: 0.8135 - val_precision: 0.9074 - val_recall: 0.6562\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 15s 333ms/step - loss: 0.0667 - Accuracy: 0.8551 - precision: 0.9062 - recall: 0.7784 - val_loss: 0.0783 - val_Accuracy: 0.8705 - val_precision: 0.8999 - val_recall: 0.7422\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 15s 327ms/step - loss: 0.0537 - Accuracy: 0.8836 - precision: 0.9232 - recall: 0.8131 - val_loss: 0.0707 - val_Accuracy: 0.8847 - val_precision: 0.9195 - val_recall: 0.7522\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 15s 324ms/step - loss: 0.0453 - Accuracy: 0.9018 - precision: 0.9358 - recall: 0.8360 - val_loss: 0.0637 - val_Accuracy: 0.8899 - val_precision: 0.9444 - val_recall: 0.7589\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 16s 356ms/step - loss: 0.0375 - Accuracy: 0.9186 - precision: 0.9500 - recall: 0.8570 - val_loss: 0.0604 - val_Accuracy: 0.9054 - val_precision: 0.9346 - val_recall: 0.7812\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 16s 338ms/step - loss: 0.0310 - Accuracy: 0.9310 - precision: 0.9624 - recall: 0.8744 - val_loss: 0.0565 - val_Accuracy: 0.9003 - val_precision: 0.9368 - val_recall: 0.7779\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 15s 329ms/step - loss: 0.0273 - Accuracy: 0.9396 - precision: 0.9673 - recall: 0.8863 - val_loss: 0.0572 - val_Accuracy: 0.8925 - val_precision: 0.9384 - val_recall: 0.7824\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 16s 342ms/step - loss: 0.0215 - Accuracy: 0.9516 - precision: 0.9776 - recall: 0.8982 - val_loss: 0.0540 - val_Accuracy: 0.9041 - val_precision: 0.9392 - val_recall: 0.7935\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 15s 323ms/step - loss: 0.0179 - Accuracy: 0.9598 - precision: 0.9840 - recall: 0.9104 - val_loss: 0.0548 - val_Accuracy: 0.9093 - val_precision: 0.9484 - val_recall: 0.8002\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 0.0165 - Accuracy: 0.9595 - precision: 0.9840 - recall: 0.9127 - val_loss: 0.0549 - val_Accuracy: 0.9003 - val_precision: 0.9382 - val_recall: 0.7958\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 16s 343ms/step - loss: 0.0139 - Accuracy: 0.9633 - precision: 0.9882 - recall: 0.9198 - val_loss: 0.0558 - val_Accuracy: 0.9145 - val_precision: 0.9460 - val_recall: 0.8013\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 14s 311ms/step - loss: 0.0121 - Accuracy: 0.9660 - precision: 0.9920 - recall: 0.9224 - val_loss: 0.0574 - val_Accuracy: 0.9041 - val_precision: 0.9392 - val_recall: 0.7924\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 15s 324ms/step - loss: 0.0107 - Accuracy: 0.9646 - precision: 0.9910 - recall: 0.9246 - val_loss: 0.0566 - val_Accuracy: 0.9041 - val_precision: 0.9490 - val_recall: 0.8103\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 15s 320ms/step - loss: 0.0118 - Accuracy: 0.9650 - precision: 0.9865 - recall: 0.9204 - val_loss: 0.0561 - val_Accuracy: 0.9067 - val_precision: 0.9424 - val_recall: 0.8036\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 16s 342ms/step - loss: 0.0075 - Accuracy: 0.9736 - precision: 0.9959 - recall: 0.9298 - val_loss: 0.0580 - val_Accuracy: 0.9145 - val_precision: 0.9465 - val_recall: 0.8092\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 14s 315ms/step - loss: 0.0066 - Accuracy: 0.9729 - precision: 0.9969 - recall: 0.9330 - val_loss: 0.0613 - val_Accuracy: 0.9132 - val_precision: 0.9428 - val_recall: 0.8092\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 18s 389ms/step - loss: 0.0053 - Accuracy: 0.9742 - precision: 0.9969 - recall: 0.9330 - val_loss: 0.0604 - val_Accuracy: 0.9080 - val_precision: 0.9467 - val_recall: 0.8125\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 14s 313ms/step - loss: 0.0047 - Accuracy: 0.9801 - precision: 0.9972 - recall: 0.9333 - val_loss: 0.0661 - val_Accuracy: 0.9106 - val_precision: 0.9442 - val_recall: 0.8114\n"
     ]
    }
   ],
   "source": [
    "r=model.fit(train_text_pad,train_labels,validation_data=(test_text_pad,test_labels),\n",
    "            epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6327cd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 36ms/step - loss: 0.0760 - Accuracy: 0.9119 - precision: 0.9481 - recall: 0.8147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07596734166145325,\n",
       " 0.9119170904159546,\n",
       " 0.948051929473877,\n",
       " 0.8147321343421936]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.evaluate(test_text_pad,test_labels)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
