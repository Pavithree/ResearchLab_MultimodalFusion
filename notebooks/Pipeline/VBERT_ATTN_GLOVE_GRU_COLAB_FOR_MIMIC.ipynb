{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgYMDvTx6fY9",
        "outputId": "1ddb531f-3cdb-43de-947f-f78bd76e85b9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n",
        "# Detectron2"
      ],
      "metadata": {
        "id": "f0659081"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd \"/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2/\"\n",
        "!pip install -r requirements.txt\n",
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "# Install detectron2\n",
        "!python setup.py build develop"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-mtteeaug\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-mtteeaug\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.29.28)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (4.63.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (0.8.9)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5->-r requirements.txt (line 1)) (0.1.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore==0.1.5->-r requirements.txt (line 1)) (2.4.0)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-lx52ix25\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-lx52ix25\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.28)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "running develop\n",
            "running egg_info\n",
            "writing detectron2.egg-info/PKG-INFO\n",
            "writing dependency_links to detectron2.egg-info/dependency_links.txt\n",
            "writing requirements to detectron2.egg-info/requires.txt\n",
            "writing top-level names to detectron2.egg-info/top_level.txt\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'detectron2.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.7/detectron2/_C.cpython-37m-x86_64-linux-gnu.so -> detectron2\n",
            "Creating /usr/local/lib/python3.7/dist-packages/detectron2.egg-link (link to .)\n",
            "detectron2 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /content/drive/MyDrive/VBERT_ATTN_GRU/detectron2\n",
            "Processing dependencies for detectron2==0.1\n",
            "Searching for imagesize==1.3.0\n",
            "Best match: imagesize 1.3.0\n",
            "Adding imagesize 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard==2.8.0\n",
            "Best match: tensorboard 2.8.0\n",
            "Adding tensorboard 2.8.0 to easy-install.pth file\n",
            "Installing tensorboard script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tqdm==4.63.0\n",
            "Best match: tqdm 4.63.0\n",
            "Adding tqdm 4.63.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for matplotlib==3.2.2\n",
            "Best match: matplotlib 3.2.2\n",
            "Adding matplotlib 3.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cloudpickle==1.3.0\n",
            "Best match: cloudpickle 1.3.0\n",
            "Adding cloudpickle 1.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tabulate==0.8.9\n",
            "Best match: tabulate 0.8.9\n",
            "Adding tabulate 0.8.9 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for yacs==0.1.8\n",
            "Best match: yacs 0.1.8\n",
            "Adding yacs 0.1.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for termcolor==1.1.0\n",
            "Best match: termcolor 1.1.0\n",
            "Adding termcolor 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Werkzeug==1.0.1\n",
            "Best match: Werkzeug 1.0.1\n",
            "Adding Werkzeug 1.0.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-data-server==0.6.1\n",
            "Best match: tensorboard-data-server 0.6.1\n",
            "Adding tensorboard-data-server 0.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth==1.35.0\n",
            "Best match: google-auth 1.35.0\n",
            "Adding google-auth 1.35.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for setuptools==57.4.0\n",
            "Best match: setuptools 57.4.0\n",
            "Adding setuptools 57.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for absl-py==1.0.0\n",
            "Best match: absl-py 1.0.0\n",
            "Adding absl-py 1.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for google-auth-oauthlib==0.4.6\n",
            "Best match: google-auth-oauthlib 0.4.6\n",
            "Adding google-auth-oauthlib 0.4.6 to easy-install.pth file\n",
            "Installing google-oauthlib-tool script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for tensorboard-plugin-wit==1.8.1\n",
            "Best match: tensorboard-plugin-wit 1.8.1\n",
            "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for grpcio==1.44.0\n",
            "Best match: grpcio 1.44.0\n",
            "Adding grpcio 1.44.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for wheel==0.37.1\n",
            "Best match: wheel 0.37.1\n",
            "Adding wheel 0.37.1 to easy-install.pth file\n",
            "Installing wheel script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.5\n",
            "Best match: numpy 1.21.5\n",
            "Adding numpy 1.21.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Markdown==3.3.6\n",
            "Best match: Markdown 3.3.6\n",
            "Adding Markdown 3.3.6 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for protobuf==3.17.3\n",
            "Best match: protobuf 3.17.3\n",
            "Adding protobuf 3.17.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for kiwisolver==1.4.0\n",
            "Best match: kiwisolver 1.4.0\n",
            "Adding kiwisolver 1.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cycler==0.11.0\n",
            "Best match: cycler 0.11.0\n",
            "Adding cycler 0.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for python-dateutil==2.8.2\n",
            "Best match: python-dateutil 2.8.2\n",
            "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyparsing==3.0.7\n",
            "Best match: pyparsing 3.0.7\n",
            "Adding pyparsing 3.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1-modules==0.2.8\n",
            "Best match: pyasn1-modules 0.2.8\n",
            "Adding pyasn1-modules 0.2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for rsa==4.8\n",
            "Best match: rsa 4.8\n",
            "Adding rsa 4.8 to easy-install.pth file\n",
            "Installing pyrsa-decrypt script to /usr/local/bin\n",
            "Installing pyrsa-encrypt script to /usr/local/bin\n",
            "Installing pyrsa-keygen script to /usr/local/bin\n",
            "Installing pyrsa-priv2pub script to /usr/local/bin\n",
            "Installing pyrsa-sign script to /usr/local/bin\n",
            "Installing pyrsa-verify script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for cachetools==4.2.4\n",
            "Best match: cachetools 4.2.4\n",
            "Adding cachetools 4.2.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests-oauthlib==1.3.1\n",
            "Best match: requests-oauthlib 1.3.1\n",
            "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.25.11\n",
            "Best match: urllib3 1.25.11\n",
            "Adding urllib3 1.25.11 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2021.10.8\n",
            "Best match: certifi 2021.10.8\n",
            "Adding certifi 2021.10.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for importlib-metadata==4.11.3\n",
            "Best match: importlib-metadata 4.11.3\n",
            "Adding importlib-metadata 4.11.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.10.0.2\n",
            "Best match: typing-extensions 3.10.0.2\n",
            "Adding typing-extensions 3.10.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for pyasn1==0.4.8\n",
            "Best match: pyasn1 0.4.8\n",
            "Adding pyasn1 0.4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for oauthlib==3.2.0\n",
            "Best match: oauthlib 3.2.0\n",
            "Adding oauthlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for zipp==3.7.0\n",
            "Best match: zipp 3.7.0\n",
            "Adding zipp 3.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for detectron2==0.1\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tYtpQKUABRC",
        "outputId": "cfc72e34-672b-45cd-b0cb-907e4004f314"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/YIKUAN8/Transformers-VQA.git\n",
        "\n",
        "#Update     args = parser.parse_args() to       args = parser.parse_args([]) in param.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Transformers-VQA'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 182 (delta 67), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (182/182), 1.94 MiB | 4.32 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSPNhawKfpwl",
        "outputId": "b9a1ad0c-fb38-4115-86cf-1227c9ee7e5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import cv2\n",
        "import pickle\n",
        "import os\n",
        "import io\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.modeling.postprocessing import detector_postprocess\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers, FastRCNNOutputs, fast_rcnn_inference_single_image"
      ],
      "outputs": [],
      "metadata": {
        "id": "b66b0666"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Image and text\n",
        "image_read = cv2.imread(\"/content/drive/MyDrive/VBERT_ATTN_GRU/test.png\")\n",
        "report = \"There is a 1.5 cm nodular opacity projecting over left hilum. The cardiac silhouette is within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of pleural effusion. There is no evidence of pneumothorax. XXXX opacities XXXX representing surgical clips, in the midline at the level of the thoracic inlet. 1. Prominence of left hilum which could be due to nodule/lymph node or superimposing blood XXXX. In the absence of prior studies for comparison, XXXX chest for further evaluation. Result notification XXXX Primordial.\""
      ],
      "outputs": [],
      "metadata": {
        "id": "Z7vBK3Wo1f20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "NUM_OBJECTS = 36\n",
        "\n",
        "# Load VG Classes\n",
        "data_path = '/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2/demo/data/genome/1600-400-20'\n",
        "\n",
        "vg_classes = []\n",
        "with open(os.path.join(data_path, 'objects_vocab.txt')) as f:\n",
        "    for object in f.readlines():\n",
        "        vg_classes.append(object.split(',')[0].lower().strip())\n",
        "\n",
        "MetadataCatalog.get(\"vg\").thing_classes = vg_classes\n",
        "\n",
        "#Config\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2/configs/VG-Detection/faster_rcnn_R_101_C4_caffe.yaml\")\n",
        "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 300\n",
        "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.6\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.2\n",
        "# VG Weight\n",
        "cfg.MODEL.WEIGHTS = \"http://nlp.cs.unc.edu/models/faster_rcnn_from_caffe.pkl\"\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "def doit(raw_image):\n",
        "    with torch.no_grad():\n",
        "        final_array = []\n",
        "        raw_height, raw_width = raw_image.shape[:2]\n",
        "        #print(\"Original image size: \", (raw_height, raw_width))\n",
        "        \n",
        "        # Preprocessing\n",
        "        image = predictor.transform_gen.get_transform(raw_image).apply_image(raw_image)\n",
        "        #print(\"Transformed image size: \", image.shape[:2])\n",
        "        image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
        "        inputs = [{\"image\": image, \"height\": raw_height, \"width\": raw_width}]\n",
        "        images = predictor.model.preprocess_image(inputs)\n",
        "        \n",
        "        # Run Backbone Res1-Res4\n",
        "        features = predictor.model.backbone(images.tensor)\n",
        "        \n",
        "        # Generate proposals with RPN\n",
        "        proposals, _ = predictor.model.proposal_generator(images, features, None)\n",
        "        proposal = proposals[0]\n",
        "        proposal_boxes = [x.proposal_boxes for x in proposals]\n",
        "        features = [features[f] for f in predictor.model.roi_heads.in_features]\n",
        "        box_features = predictor.model.roi_heads._shared_roi_transform(\n",
        "            features, proposal_boxes\n",
        "        )\n",
        "        feature_pooled = box_features.mean(dim=[2, 3])  # pooled to 1x1\n",
        "        pred_class_logits, pred_proposal_deltas = predictor.model.roi_heads.box_predictor(feature_pooled)\n",
        "        outputs = FastRCNNOutputs(\n",
        "            predictor.model.roi_heads.box2box_transform,\n",
        "            pred_class_logits,\n",
        "            pred_proposal_deltas,\n",
        "            proposals,\n",
        "            predictor.model.roi_heads.smooth_l1_beta,\n",
        "        )\n",
        "        probs = outputs.predict_probs()[0]\n",
        "        boxes = outputs.predict_boxes()[0]\n",
        "        \n",
        "        for nms_thresh in np.arange(0.5, 1.0, 0.1):\n",
        "            instances, ids = fast_rcnn_inference_single_image(\n",
        "                boxes, probs, image.shape[1:], \n",
        "                score_thresh=0, nms_thresh=nms_thresh, topk_per_image=NUM_OBJECTS\n",
        "            )\n",
        "            if len(ids) == NUM_OBJECTS:\n",
        "                break\n",
        "                \n",
        "        instances = detector_postprocess(instances, raw_height, raw_width)\n",
        "        roi_features = feature_pooled[ids].detach()\n",
        "        final_array.append(roi_features.cpu().numpy())\n",
        "        final_array.append(instances.pred_boxes.tensor.cpu().numpy())\n",
        "        final_array.append(raw_height)\n",
        "        final_array.append(raw_width)\n",
        "        return final_array\n",
        "\n",
        "#Feature exrtraction\n",
        "feature, bbox, img_w, img_h = doit(image_read)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/07 05:13:32 d2.config.compat]: \u001b[0mConfig '/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2/configs/VG-Detection/faster_rcnn_R_101_C4_caffe.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
            "Modifications for VG in RPN (modeling/proposal_generator/rpn.py):\n",
            "\tUse hidden dim 512 instead fo the same dim as Res4 (1024).\n",
            "\n",
            "Modifications for VG in RoI heads (modeling/roi_heads/roi_heads.py):\n",
            "\t1. Change the stride of conv1 and shortcut in Res5.Block1 from 2 to 1.\n",
            "\t2. Modifying all conv2 with (padding: 1 --> 2) and (dilation: 1 --> 2).\n",
            "\tFor more details, please check 'https://github.com/peteanderson80/bottom-up-attention/blob/master/models/vg/ResNet-101/faster_rcnn_end2end_final/test.prototxt'.\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774b80dc",
        "outputId": "58f8023a-46d2-48bb-b19a-79e71c4d7d85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VisualBERT\n"
      ],
      "metadata": {
        "id": "LdZgRigps75q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-kGJ9czXs5yB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd Transformers-VQA/\n",
        "!pip install -r requirements.txt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/VBERT_ATTN_GRU/detectron2/Transformers-VQA\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.63.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.21.35)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.21.5)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.35 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 10)) (1.24.35)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->-r requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.35->boto3->-r requirements.txt (line 10)) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.35->boto3->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.35->boto3->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 12)) (2.10)\n"
          ]
        }
      ],
      "metadata": {
        "id": "1b0c33cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30fd149-3753-46e9-9b6a-e0c7271a83d3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "VBERT_model = torch.load('/content/drive/MyDrive/VBERT_ATTN_GRU/VBertMIMIC.pt');"
      ],
      "outputs": [],
      "metadata": {
        "id": "7JCjVnOfhobg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ftr_r = np.reshape(feature, (1,36,2048))\n",
        "box_r = np.reshape(bbox, (1,36,4))\n",
        "bbox = torch.from_numpy(box_r)\n",
        "feature = torch.from_numpy(ftr_r)"
      ],
      "outputs": [],
      "metadata": {
        "id": "fAJnRFzyltlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sgmd = torch.nn.Sigmoid()\n",
        "logit = VBERT_model(feature.cuda(), bbox.cuda(),  report)\n",
        "result_VBert = sgmd(logit).cpu().numpy();"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEXT PREPROCESSING\n"
      ],
      "metadata": {
        "id": "9loTp3m32X5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tqdm import tqdm\n",
        "!pip install neattext\n",
        "import neattext.functions as nfx\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer=Tokenizer();\n",
        "\n",
        "def clean_text(text):\n",
        "    text_length=[]\n",
        "    cleaned_text=[]\n",
        "    for sent in tqdm(text):\n",
        "        sent=sent.lower()\n",
        "        sent=nfx.remove_special_characters(sent)\n",
        "        sent=nfx.remove_stopwords(sent)\n",
        "        text_length.append(len(sent.split()))\n",
        "        cleaned_text.append(sent)\n",
        "    return cleaned_text,text_length\n",
        "\n",
        "cleaned_report, cleaned_report_length = clean_text(report)\n",
        "report_seq=tokenizer.texts_to_sequences(cleaned_report)\n",
        "report_pad=pad_sequences(report_seq,maxlen=50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neattext in /usr/local/lib/python3.7/dist-packages (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 565/565 [00:00<00:00, 102419.47it/s]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_nmQUz62ncN",
        "outputId": "3b4975b8-aacd-4a91-e171-645ddbe30fdb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_NLP = tf.keras.models.load_model(\"/content/drive/MyDrive/VBERT_ATTN_GRU/NLP_mimic\")\n",
        "result_NLP = model_NLP.predict(report_pad, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,workers=1, use_multiprocessing=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "65vxYXSYsXEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Late Fusion\n"
      ],
      "metadata": {
        "id": "CxTQY4-0uYEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "late_fusion_model = tf.keras.models.load_model(\"/content/drive/MyDrive/VBERT_ATTN_GRU/lateFusionMIMIC.h5\")\n",
        "input_FeatureVector = result_NLP.tolist() + result_VBert.tolist()\n",
        "result_late_fusion_model = model_NLP.predict(input_FeatureVector, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,workers=1, use_multiprocessing=False)\n",
        "print(result_late_fusion_model)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_NLP.predict(input_FeatureVector, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,workers=1, use_multiprocessing=False)\n",
        "print(result_late_fusion_model)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "VBERT_ATTN_GLOVE_GRU_COLAB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}